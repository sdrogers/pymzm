{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv,os,glob\n",
    "output_dir = 'batch20/output_subset/'\n",
    "aligned_csv = 'pp_aligned.csv'\n",
    "align_file = os.path.join(output_dir,aligned_csv)\n",
    "\n",
    "# make a list of the original files -- these should be without any extension\n",
    "original_files = ['Urine_StrokeDrugs_105_T10_POS','Urine_StrokeDrugs_18_T10_POS','Urine_StrokeDrugs_58_T10_POS']\n",
    "\n",
    "original_files = glob.glob(os.path.join(output_dir,'*.mgf'))\n",
    "original_files = [o.split(os.sep)[-1].split('.')[0] for o in original_files]\n",
    "print(original_files)\n",
    "\n",
    "original_csvs = [os.path.join(output_dir,original_file + '_quant.csv') for original_file in original_files]\n",
    "aligned_peaks = []\n",
    "f_idx_dict =  {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the aligned peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(align_file,'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    heads = next(reader)\n",
    "    file_bits = heads[3:]\n",
    "    for o in original_files:\n",
    "        temp = [1 if f.startswith(o) else 0 for f in file_bits]\n",
    "        f_idx_dict[o] = temp.index(1)\n",
    "    for line in reader:\n",
    "        align_id = int(line[0])\n",
    "        align_mz = float(line[1])\n",
    "        align_rt = float(line[2])\n",
    "        intensities = tuple([float(a) for a in line[3:-1]])\n",
    "        aligned_peaks.append((align_id,align_mz,align_rt,intensities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = np.array([list(a[3]) for a in aligned_peaks])\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.log(intensities+1),aspect='auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_intensities = intensities * (intensities > 5e5)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.log(trunc_intensities+1),aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match the local peaks (i.e. from the original csvs) to the aligned ones\n",
    "\n",
    "- Done based upon intensity as there should be exact intensity matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = {}\n",
    "for file_pos,o in enumerate(original_files):\n",
    "    with open(original_csvs[file_pos],'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        heads = next(reader)\n",
    "        local_peaks = []\n",
    "        for line in reader:\n",
    "            id = int(line[0])\n",
    "            mz = float(line[1])\n",
    "            rt = float(line[2])\n",
    "            intensity = float(line[3])\n",
    "            local_peaks.append((id,mz,rt,intensity))\n",
    "    local_peaks.sort(key = lambda x: x[3], reverse = True)\n",
    "    this_idx = f_idx_dict[o]\n",
    "    aligned_peaks.sort(key = lambda x: x[3][this_idx],reverse = True)\n",
    "    local_pos = 0\n",
    "    global_pos = 0\n",
    "    while local_pos < len(local_peaks) and local_peaks[local_pos][3] > 0:\n",
    "        #Â find the match in the global pos\n",
    "        while abs(aligned_peaks[global_pos][3][this_idx] - local_peaks[local_pos][3]) > 1:\n",
    "            global_pos += 1\n",
    "        if not aligned_peaks[global_pos] in matches:\n",
    "            matches[aligned_peaks[global_pos]] = {}\n",
    "        matches[aligned_peaks[global_pos]][o] = local_peaks[local_pos]\n",
    "        local_pos += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write an output - don't need to run this unless you want the links in a file\n",
    "output_file = os.path.join(output_dir,'align_links.csv')\n",
    "with open(output_file,'w') as f:\n",
    "    heads = ['align ID','row m/z','row retention time'] + original_files\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(heads)\n",
    "    for aligned_peak in matches:\n",
    "        new_row = [aligned_peak[0],aligned_peak[1],aligned_peak[2]]\n",
    "        for o in original_files:\n",
    "            val = matches[aligned_peak].get(o,None)\n",
    "            if val:\n",
    "                new_row.append(val[0])\n",
    "            else:\n",
    "                new_row.append('null')\n",
    "        writer.writerow(new_row)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = {}\n",
    "from MS2 import load_mgf\n",
    "for o in original_files:\n",
    "    mgf_file = os.path.join(output_dir,o+'.mgf')\n",
    "    spectra[o] = load_mgf(mgf_file)\n",
    "    print(\"Loaded {} spectra from {}\".format(len(spectra[o]),o))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute similarity between aligned peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "from scoring_functions import fast_cosine\n",
    "for aligned_peak in matches:\n",
    "    for i in range(len(original_files))[:-1]:\n",
    "        for j in range(i+1,len(original_files)):\n",
    "            file_i = original_files[i]\n",
    "            file_j = original_files[j]\n",
    "            if file_i in matches[aligned_peak] and file_j in matches[aligned_peak]:\n",
    "                id_i = matches[aligned_peak][file_i][0]\n",
    "                id_j = matches[aligned_peak][file_j][0]\n",
    "                spec_i = spectra[file_i].get(id_i,None)\n",
    "                spec_j = spectra[file_j].get(id_j,None)\n",
    "                if spec_i and spec_j:\n",
    "                    sc,_ = fast_cosine(spec_i,spec_j,0.2,1)\n",
    "#                     print(file_i,file_j,spec_i.rt,spec_j.rt,sc)\n",
    "                    lines.append((file_i,file_j,60*matches[aligned_peak][file_i][2],60*matches[aligned_peak][file_j][2],sc))\n",
    "                    print(file_i,file_j,60*matches[aligned_peak][file_i][2],60*matches[aligned_peak][file_j][2],sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter(lambda x: x[4] > 0.9,lines)\n",
    "a,b,_,_,_ = zip(*filtered)\n",
    "a = list(a) + list(b)\n",
    "c = set(a)\n",
    "counts = []\n",
    "for d in c:\n",
    "    counts.append((d,a.count(d)))\n",
    "counts.sort(key = lambda x: x[1],reverse = True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out a new mzTab file with corrected RTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_file = 'Pool107_03'\n",
    "\n",
    "for fi in original_files:        \n",
    "    print(fi)\n",
    "    if fi == reference_file:\n",
    "        continue\n",
    "    # train the model\n",
    "    file_1 = reference_file\n",
    "    file_2 = fi\n",
    "    subset = []\n",
    "    min_cosine = 0.9\n",
    "    for line in lines:\n",
    "        if line[4] < min_cosine:\n",
    "            continue\n",
    "        if line[0] == file_1 and line[1] == file_2:\n",
    "            subset.append(line)\n",
    "        elif line[1] == file_1 and line[0] == file_2:\n",
    "            new_line = (line[1],line[0],line[2],line[3],line[4])\n",
    "            subset.append(new_line)\n",
    "    _,_,t1,t2,cos = zip(*subset)\n",
    "    t1 = np.array(t1)\n",
    "    t2 = np.array(t2)\n",
    "    kernel = GPy.kern.RBF(input_dim=1, variance=3., lengthscale=67.)\n",
    "    X = t2[:,None]\n",
    "    Y = (t1-t2)[:,None]\n",
    "    m = GPy.models.GPRegression(X,Y,kernel)\n",
    "    m.plot()\n",
    "    with open(os.path.join(output_dir,file_2+'_pp.mzTab'),'r') as f:\n",
    "        with open(os.path.join('batch20/sub_new_files/'+file_2+'_pp.mzTab'),'w') as g:\n",
    "            for line in f:\n",
    "                line = line.rstrip()\n",
    "                if line.startswith('SMH'):\n",
    "                    tokens = line.split()\n",
    "                    rt_pos = [tokens.index('retention_time')]\n",
    "                    rt_pos.append(tokens.index('opt_assay[1]_peak_rt'))\n",
    "                if not line.startswith('SML'):\n",
    "                    g.write(line + '\\n')\n",
    "                else:\n",
    "                    tokens = line.split()\n",
    "                    old_rt = 60.0*float(tokens[rt_pos[0]])\n",
    "                    new_rt,_ = m.predict(np.array([[old_rt]]))\n",
    "                    new_rt = new_rt[0][0]\n",
    "                    new_rt += old_rt\n",
    "                    new_rt/=60.0\n",
    "                    tokens[rt_pos[0]] = new_rt\n",
    "                    tokens[rt_pos[1]] = new_rt\n",
    "                    new_line = '\\t'.join([str(t) for t in tokens])\n",
    "                    g.write(new_line + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = 0\n",
    "for i in range(len(aligned_peaks)-1):\n",
    "    p_i = aligned_peaks[i]\n",
    "    for j in range(i+1,len(aligned_peaks)):\n",
    "        p_j = aligned_peaks[j]\n",
    "        if abs(p_i[1] - p_j[1]) < 0.001:\n",
    "            if abs(p_i[2] - p_j[2]) < 5./60.0:\n",
    "                for k in range(3):\n",
    "                    print(p_i[k],p_j[k])\n",
    "                i_1 = p_i[3]\n",
    "                i_2 = p_j[3]\n",
    "                for k in range(len(i_1)):\n",
    "                    print(i_1[k],i_2[k])\n",
    "                found +=1\n",
    "                print()\n",
    "                print()\n",
    "    if found > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
